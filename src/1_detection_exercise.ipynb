{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bce9f3",
   "metadata": {},
   "source": [
    "# Object Detection(객체 탐지) : YOLO (You Only Look Onece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d4ba3",
   "metadata": {},
   "source": [
    "`uv add ultralytics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf36a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176c436",
   "metadata": {},
   "source": [
    "# 1. 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7f9d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:\\Potenup\\DeepLearning-YOLO-Study\\models\\yolo11n.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "361729ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path) # 모델 저장 경로 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1da68",
   "metadata": {},
   "source": [
    "# 2. 이미지 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd1bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 7 persons, 3 bicycles, 1 umbrella, 50.9ms\n",
      "1: 640x640 1 cat, 50.9ms\n",
      "Speed: 2.5ms preprocess, 50.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Potenup\\DeepLearning-YOLO-Study\\runs\\detect\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 이미지들의 경로를 리스트로 작성\n",
    "results = model.predict([\"C:\\Potenup\\DeepLearning-YOLO-Study\\images\\yolo_image.jpg\", \"C:\\Potenup\\DeepLearning-YOLO-Study\\images\\cat_test.jpg\"], save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c22197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 7 persons, 3 bicycles, 1 umbrella, 162.8ms\n",
      "Speed: 5.8ms preprocess, 162.8ms inference, 2.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mC:\\Potenup\\DeepLearning-YOLO-Study\\runs\\detect\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[209, 191, 168],\n",
       "         [209, 191, 168],\n",
       "         [210, 192, 169],\n",
       "         ...,\n",
       "         [214, 197, 178],\n",
       "         [215, 198, 179],\n",
       "         [216, 199, 180]],\n",
       " \n",
       "        [[208, 190, 167],\n",
       "         [208, 190, 167],\n",
       "         [209, 191, 168],\n",
       "         ...,\n",
       "         [213, 196, 177],\n",
       "         [213, 196, 177],\n",
       "         [213, 196, 177]],\n",
       " \n",
       "        [[208, 190, 167],\n",
       "         [208, 190, 167],\n",
       "         [209, 191, 168],\n",
       "         ...,\n",
       "         [214, 197, 178],\n",
       "         [214, 197, 178],\n",
       "         [214, 197, 178]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[126, 145, 158],\n",
       "         [118, 137, 150],\n",
       "         [121, 140, 153],\n",
       "         ...,\n",
       "         [130, 159, 164],\n",
       "         [116, 147, 150],\n",
       "         [124, 155, 156]],\n",
       " \n",
       "        [[117, 137, 148],\n",
       "         [102, 122, 133],\n",
       "         [116, 136, 147],\n",
       "         ...,\n",
       "         [134, 160, 167],\n",
       "         [122, 151, 156],\n",
       "         [130, 159, 163]],\n",
       " \n",
       "        [[119, 140, 148],\n",
       "         [105, 126, 134],\n",
       "         [ 98, 119, 127],\n",
       "         ...,\n",
       "         [128, 154, 161],\n",
       "         [128, 154, 161],\n",
       "         [140, 166, 172]]], shape=(854, 1280, 3), dtype=uint8)\n",
       " orig_shape: (854, 1280)\n",
       " path: 'C:\\\\Potenup\\\\DeepLearning-YOLO-Study\\\\images\\\\yolo_image.jpg'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Potenup\\\\DeepLearning-YOLO-Study\\\\runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 5.818699952214956, 'inference': 162.8030000720173, 'postprocess': 2.8995999600738287}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model([\"C:\\Potenup\\DeepLearning-YOLO-Study\\images\\yolo_image.jpg\"], save=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a703d21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "obb: None\n",
       "orig_img: array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], shape=(619, 600, 3), dtype=uint8)\n",
       "orig_shape: (619, 600)\n",
       "path: 'C:\\\\Potenup\\\\DeepLearning-YOLO-Study\\\\images\\\\cat_test.jpg'\n",
       "probs: None\n",
       "save_dir: 'C:\\\\Potenup\\\\DeepLearning-YOLO-Study\\\\runs\\\\detect\\\\predict2'\n",
       "speed: {'preprocess': 2.4800500250421464, 'inference': 50.941099994815886, 'postprocess': 1.1612999951466918}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f0893",
   "metadata": {},
   "source": [
    "## 1) `results` 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5e971",
   "metadata": {},
   "source": [
    "### 예측한 이미지 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d2d16",
   "metadata": {},
   "source": [
    "### 예측 결과 이미지 보기 & 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e768900",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b448a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    result.show()                   # 화면에 결과 이미지 보여짐\n",
    "    # result.save(filename=\"C:\\Potenup\\DeepLearning-YOLO-Study\\\\results\\yolo_image_result.jpg\")  # 예측 이미지 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625e75c",
   "metadata": {},
   "source": [
    "### 클래스 딕셔너리 가져오기\n",
    "- COCO 데이터셋 제공 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1e0a42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = results[0].names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2a80d8",
   "metadata": {},
   "source": [
    "### 정리\n",
    "- results --- 예측한 이미지 개수만큼 리스트로 담겨 있음 \n",
    "- len(results)\n",
    "- results.names --- 딕셔너리로 탐지할 수 있는 객체 저장되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7ec3e",
   "metadata": {},
   "source": [
    "## 2) 예측 결과 확인하기 : `result.boxes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d789754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.boxes : 탐지된 객체 인식한 박스 정보들이 들어가 있음\n",
    "\n",
    "# boxes.cls: 객체 예측한 결과\n",
    "# boxes.conf: 예측 신뢰도\n",
    "# boxes.data: (x1, y1, x2, y2, conf, cls) 박스좌표(x1, y1, x2, y2), 신뢰도(conf), 결과(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a59eb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([ 1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0., 25.,  0.])\n",
       "conf: tensor([0.8982, 0.8669, 0.8391, 0.8209, 0.7041, 0.6857, 0.5401, 0.3992, 0.3409, 0.3104, 0.2839])\n",
       "data: tensor([[6.2619e+02, 3.9398e+02, 1.0356e+03, 7.7133e+02, 8.9817e-01, 1.0000e+00],\n",
       "        [3.8493e+02, 2.1335e+02, 5.8395e+02, 7.4493e+02, 8.6687e-01, 0.0000e+00],\n",
       "        [3.1186e+02, 4.3126e+02, 6.2193e+02, 7.6603e+02, 8.3909e-01, 1.0000e+00],\n",
       "        [2.0884e+01, 3.8376e+02, 2.8009e+02, 6.5648e+02, 8.2086e-01, 1.0000e+00],\n",
       "        [8.3118e+02, 1.8194e+02, 1.0133e+03, 7.0894e+02, 7.0407e-01, 0.0000e+00],\n",
       "        [1.1814e+02, 2.4419e+02, 2.8157e+02, 6.3590e+02, 6.8566e-01, 0.0000e+00],\n",
       "        [5.9455e+02, 2.1387e+02, 7.9375e+02, 6.7405e+02, 5.4014e-01, 0.0000e+00],\n",
       "        [3.4304e+02, 2.5966e+02, 4.2504e+02, 4.9061e+02, 3.9924e-01, 0.0000e+00],\n",
       "        [5.9239e+02, 2.1504e+02, 7.9454e+02, 4.2751e+02, 3.4094e-01, 0.0000e+00],\n",
       "        [3.3748e+02, 2.1152e+02, 5.3818e+02, 3.0389e+02, 3.1044e-01, 2.5000e+01],\n",
       "        [1.1929e+02, 2.4307e+02, 2.8095e+02, 5.0486e+02, 2.8390e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (854, 1280)\n",
       "shape: torch.Size([11, 6])\n",
       "xywh: tensor([[830.9132, 582.6562, 409.4492, 377.3562],\n",
       "        [484.4370, 479.1396, 199.0198, 531.5872],\n",
       "        [466.8965, 598.6458, 310.0638, 334.7632],\n",
       "        [150.4875, 520.1235, 259.2061, 272.7190],\n",
       "        [922.2227, 445.4365, 182.0953, 527.0005],\n",
       "        [199.8519, 440.0416, 163.4276, 391.7090],\n",
       "        [694.1482, 443.9565, 199.1963, 460.1791],\n",
       "        [384.0355, 375.1344,  81.9996, 230.9458],\n",
       "        [693.4618, 321.2729, 202.1470, 212.4731],\n",
       "        [437.8286, 257.7081, 200.7009,  92.3667],\n",
       "        [200.1202, 373.9698, 161.6601, 261.7899]])\n",
       "xywhn: tensor([[0.6492, 0.6823, 0.3199, 0.4419],\n",
       "        [0.3785, 0.5611, 0.1555, 0.6225],\n",
       "        [0.3648, 0.7010, 0.2422, 0.3920],\n",
       "        [0.1176, 0.6090, 0.2025, 0.3193],\n",
       "        [0.7205, 0.5216, 0.1423, 0.6171],\n",
       "        [0.1561, 0.5153, 0.1277, 0.4587],\n",
       "        [0.5423, 0.5199, 0.1556, 0.5389],\n",
       "        [0.3000, 0.4393, 0.0641, 0.2704],\n",
       "        [0.5418, 0.3762, 0.1579, 0.2488],\n",
       "        [0.3421, 0.3018, 0.1568, 0.1082],\n",
       "        [0.1563, 0.4379, 0.1263, 0.3065]])\n",
       "xyxy: tensor([[ 626.1886,  393.9781, 1035.6378,  771.3344],\n",
       "        [ 384.9271,  213.3460,  583.9469,  744.9332],\n",
       "        [ 311.8646,  431.2642,  621.9285,  766.0273],\n",
       "        [  20.8845,  383.7640,  280.0905,  656.4830],\n",
       "        [ 831.1750,  181.9363, 1013.2704,  708.9368],\n",
       "        [ 118.1381,  244.1871,  281.5656,  635.8961],\n",
       "        [ 594.5500,  213.8670,  793.7463,  674.0461],\n",
       "        [ 343.0356,  259.6615,  425.0353,  490.6073],\n",
       "        [ 592.3883,  215.0364,  794.5353,  427.5095],\n",
       "        [ 337.4782,  211.5248,  538.1791,  303.8915],\n",
       "        [ 119.2901,  243.0748,  280.9502,  504.8647]])\n",
       "xyxyn: tensor([[0.4892, 0.4613, 0.8091, 0.9032],\n",
       "        [0.3007, 0.2498, 0.4562, 0.8723],\n",
       "        [0.2436, 0.5050, 0.4859, 0.8970],\n",
       "        [0.0163, 0.4494, 0.2188, 0.7687],\n",
       "        [0.6494, 0.2130, 0.7916, 0.8301],\n",
       "        [0.0923, 0.2859, 0.2200, 0.7446],\n",
       "        [0.4645, 0.2504, 0.6201, 0.7893],\n",
       "        [0.2680, 0.3041, 0.3321, 0.5745],\n",
       "        [0.4628, 0.2518, 0.6207, 0.5006],\n",
       "        [0.2637, 0.2477, 0.4205, 0.3558],\n",
       "        [0.0932, 0.2846, 0.2195, 0.5912]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84d18e",
   "metadata": {},
   "source": [
    "### 이미지에서 찾은 객체 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95ec43a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results[0].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd82d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.shape # (객체 수, data의 칼럼 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda96b9",
   "metadata": {},
   "source": [
    "### 예측 결과, 신뢰도 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5be05e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터타입\t<class 'ultralytics.engine.results.Boxes'>\n",
      "예측결과\t\ttensor([ 1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0., 25.,  0.])\n",
      "신뢰도\t\ttensor([0.8982, 0.8669, 0.8391, 0.8209, 0.7041, 0.6857, 0.5401, 0.3992, 0.3409, 0.3104, 0.2839])\n",
      "데이터\t\ttensor([[6.2619e+02, 3.9398e+02, 1.0356e+03, 7.7133e+02, 8.9817e-01, 1.0000e+00],\n",
      "        [3.8493e+02, 2.1335e+02, 5.8395e+02, 7.4493e+02, 8.6687e-01, 0.0000e+00],\n",
      "        [3.1186e+02, 4.3126e+02, 6.2193e+02, 7.6603e+02, 8.3909e-01, 1.0000e+00],\n",
      "        [2.0884e+01, 3.8376e+02, 2.8009e+02, 6.5648e+02, 8.2086e-01, 1.0000e+00],\n",
      "        [8.3118e+02, 1.8194e+02, 1.0133e+03, 7.0894e+02, 7.0407e-01, 0.0000e+00],\n",
      "        [1.1814e+02, 2.4419e+02, 2.8157e+02, 6.3590e+02, 6.8566e-01, 0.0000e+00],\n",
      "        [5.9455e+02, 2.1387e+02, 7.9375e+02, 6.7405e+02, 5.4014e-01, 0.0000e+00],\n",
      "        [3.4304e+02, 2.5966e+02, 4.2504e+02, 4.9061e+02, 3.9924e-01, 0.0000e+00],\n",
      "        [5.9239e+02, 2.1504e+02, 7.9454e+02, 4.2751e+02, 3.4094e-01, 0.0000e+00],\n",
      "        [3.3748e+02, 2.1152e+02, 5.3818e+02, 3.0389e+02, 3.1044e-01, 2.5000e+01],\n",
      "        [1.1929e+02, 2.4307e+02, 2.8095e+02, 5.0486e+02, 2.8390e-01, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Object 출력해보기\n",
    "result = results[0]\n",
    "boxes = result.boxes\n",
    "print(f\"데이터타입\\t{type(boxes)}\")\n",
    "print(f\"예측결과\\t\\t{boxes.cls}\") # 탐지한 객체 예측 결과\n",
    "print(f\"신뢰도\\t\\t{boxes.conf}\") # 각 객체에 대한 예측 신뢰도\n",
    "print(f\"데이터\\t\\t{boxes.data}\") # 각 객체에 대한 [x1, y1, x2, y2, conf, cls] > 박스좌표, 신뢰도, 예측결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b93da4",
   "metadata": {},
   "source": [
    "### 클래스 딕셔너리와 예측 결과 매칭하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45945027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d15fb82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bicycle'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ece03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = {0 : 'person', 1 : 'bicycle' ... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a7bd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle을/를 찾았습니다!\n",
      "person을/를 찾았습니다!\n",
      "bicycle을/를 찾았습니다!\n",
      "bicycle을/를 찾았습니다!\n",
      "person을/를 찾았습니다!\n",
      "person을/를 찾았습니다!\n",
      "person을/를 찾았습니다!\n",
      "person을/를 찾았습니다!\n",
      "person을/를 찾았습니다!\n",
      "umbrella을/를 찾았습니다!\n",
      "person을/를 찾았습니다!\n"
     ]
    }
   ],
   "source": [
    "for cls in boxes.cls:\n",
    "    print(f'{class_names[cls.item()]}을/를 찾았습니다!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf11365",
   "metadata": {},
   "source": [
    "### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "142048f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(626.1886) tensor(393.9781) tensor(1035.6378) tensor(771.3344) tensor(0.8982) tensor(1.) bicycle\n",
      "tensor(384.9271) tensor(213.3460) tensor(583.9469) tensor(744.9332) tensor(0.8669) tensor(0.) person\n",
      "tensor(311.8646) tensor(431.2642) tensor(621.9285) tensor(766.0273) tensor(0.8391) tensor(1.) bicycle\n",
      "tensor(20.8845) tensor(383.7640) tensor(280.0905) tensor(656.4830) tensor(0.8209) tensor(1.) bicycle\n",
      "tensor(831.1750) tensor(181.9363) tensor(1013.2704) tensor(708.9368) tensor(0.7041) tensor(0.) person\n",
      "tensor(118.1381) tensor(244.1871) tensor(281.5656) tensor(635.8961) tensor(0.6857) tensor(0.) person\n",
      "tensor(594.5500) tensor(213.8670) tensor(793.7463) tensor(674.0461) tensor(0.5401) tensor(0.) person\n",
      "tensor(343.0356) tensor(259.6615) tensor(425.0353) tensor(490.6073) tensor(0.3992) tensor(0.) person\n",
      "tensor(592.3883) tensor(215.0364) tensor(794.5353) tensor(427.5095) tensor(0.3409) tensor(0.) person\n",
      "tensor(337.4782) tensor(211.5248) tensor(538.1791) tensor(303.8915) tensor(0.3104) tensor(25.) umbrella\n",
      "tensor(119.2901) tensor(243.0748) tensor(280.9502) tensor(504.8647) tensor(0.2839) tensor(0.) person\n"
     ]
    }
   ],
   "source": [
    "for x1, y1, x2, y2, conf, cls in boxes.data: # (x1, y1, x2, y2, conf, cls)\n",
    "    print(x1, y1, x2, y2, conf, cls, class_names[cls.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d66eccd",
   "metadata": {},
   "source": [
    "# 3. 영상 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eaa404",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://youtu.be/S5nsDT5oU90\"\n",
    "\n",
    "results = model(youtube_url, stream=True, show=True)\n",
    "\n",
    "for res in results:\n",
    "    print(res.boxes.cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b832b6",
   "metadata": {},
   "source": [
    "# YOLO와 비슷한 오픈 소스 \n",
    "- Fast CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning-YOLO-Study (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
